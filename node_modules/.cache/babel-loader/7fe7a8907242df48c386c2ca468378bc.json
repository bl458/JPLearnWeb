{"ast":null,"code":"/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\"use strict\";\n\nvar ByteBuffer = require(\"../util/ByteBuffer\");\n/**\n * TokenInfoDictionary\n * @constructor\n */\n\n\nfunction TokenInfoDictionary() {\n  this.dictionary = new ByteBuffer(10 * 1024 * 1024);\n  this.target_map = {}; // trie_id (of surface form) -> token_info_id (of token)\n\n  this.pos_buffer = new ByteBuffer(10 * 1024 * 1024);\n} // left_id right_id word_cost ...\n// ^ this position is token_info_id\n\n\nTokenInfoDictionary.prototype.buildDictionary = function (entries) {\n  var dictionary_entries = {}; // using as hashmap, string -> string (word_id -> surface_form) to build dictionary\n\n  for (var i = 0; i < entries.length; i++) {\n    var entry = entries[i];\n\n    if (entry.length < 4) {\n      continue;\n    }\n\n    var surface_form = entry[0];\n    var left_id = entry[1];\n    var right_id = entry[2];\n    var word_cost = entry[3];\n    var feature = entry.slice(4).join(\",\"); // TODO Optimize\n    // Assertion\n\n    if (!isFinite(left_id) || !isFinite(right_id) || !isFinite(word_cost)) {\n      console.log(entry);\n    }\n\n    var token_info_id = this.put(left_id, right_id, word_cost, surface_form, feature);\n    dictionary_entries[token_info_id] = surface_form;\n  } // Remove last unused area\n\n\n  this.dictionary.shrink();\n  this.pos_buffer.shrink();\n  return dictionary_entries;\n};\n\nTokenInfoDictionary.prototype.put = function (left_id, right_id, word_cost, surface_form, feature) {\n  var token_info_id = this.dictionary.position;\n  var pos_id = this.pos_buffer.position;\n  this.dictionary.putShort(left_id);\n  this.dictionary.putShort(right_id);\n  this.dictionary.putShort(word_cost);\n  this.dictionary.putInt(pos_id);\n  this.pos_buffer.putString(surface_form + \",\" + feature);\n  return token_info_id;\n};\n\nTokenInfoDictionary.prototype.addMapping = function (source, target) {\n  var mapping = this.target_map[source];\n\n  if (mapping == null) {\n    mapping = [];\n  }\n\n  mapping.push(target);\n  this.target_map[source] = mapping;\n};\n\nTokenInfoDictionary.prototype.targetMapToBuffer = function () {\n  var buffer = new ByteBuffer();\n  var map_keys_size = Object.keys(this.target_map).length;\n  buffer.putInt(map_keys_size);\n\n  for (var key in this.target_map) {\n    var values = this.target_map[key]; // Array\n\n    var map_values_size = values.length;\n    buffer.putInt(parseInt(key));\n    buffer.putInt(map_values_size);\n\n    for (var i = 0; i < values.length; i++) {\n      buffer.putInt(values[i]);\n    }\n  }\n\n  return buffer.shrink(); // Shrink-ed Typed Array\n}; // from tid.dat\n\n\nTokenInfoDictionary.prototype.loadDictionary = function (array_buffer) {\n  this.dictionary = new ByteBuffer(array_buffer);\n  return this;\n}; // from tid_pos.dat\n\n\nTokenInfoDictionary.prototype.loadPosVector = function (array_buffer) {\n  this.pos_buffer = new ByteBuffer(array_buffer);\n  return this;\n}; // from tid_map.dat\n\n\nTokenInfoDictionary.prototype.loadTargetMap = function (array_buffer) {\n  var buffer = new ByteBuffer(array_buffer);\n  buffer.position = 0;\n  this.target_map = {};\n  buffer.readInt(); // map_keys_size\n\n  while (true) {\n    if (buffer.buffer.length < buffer.position + 1) {\n      break;\n    }\n\n    var key = buffer.readInt();\n    var map_values_size = buffer.readInt();\n\n    for (var i = 0; i < map_values_size; i++) {\n      var value = buffer.readInt();\n      this.addMapping(key, value);\n    }\n  }\n\n  return this;\n};\n/**\n * Look up features in the dictionary\n * @param {string} token_info_id_str Word ID to look up\n * @returns {string} Features string concatenated by \",\"\n */\n\n\nTokenInfoDictionary.prototype.getFeatures = function (token_info_id_str) {\n  var token_info_id = parseInt(token_info_id_str);\n\n  if (isNaN(token_info_id)) {\n    // TODO throw error\n    return \"\";\n  }\n\n  var pos_id = this.dictionary.getInt(token_info_id + 6);\n  return this.pos_buffer.getString(pos_id);\n};\n\nmodule.exports = TokenInfoDictionary;","map":{"version":3,"sources":["/home/byungchan/Projects/JapaneseQuiz/node_modules/kuromoji/src/dict/TokenInfoDictionary.js"],"names":["ByteBuffer","require","TokenInfoDictionary","dictionary","target_map","pos_buffer","prototype","buildDictionary","entries","dictionary_entries","i","length","entry","surface_form","left_id","right_id","word_cost","feature","slice","join","isFinite","console","log","token_info_id","put","shrink","position","pos_id","putShort","putInt","putString","addMapping","source","target","mapping","push","targetMapToBuffer","buffer","map_keys_size","Object","keys","key","values","map_values_size","parseInt","loadDictionary","array_buffer","loadPosVector","loadTargetMap","readInt","value","getFeatures","token_info_id_str","isNaN","getInt","getString","module","exports"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA;;AAEA,IAAIA,UAAU,GAAGC,OAAO,CAAC,oBAAD,CAAxB;AAEA;;;;;;AAIA,SAASC,mBAAT,GAA+B;AAC3B,OAAKC,UAAL,GAAkB,IAAIH,UAAJ,CAAe,KAAK,IAAL,GAAY,IAA3B,CAAlB;AACA,OAAKI,UAAL,GAAkB,EAAlB,CAF2B,CAEJ;;AACvB,OAAKC,UAAL,GAAkB,IAAIL,UAAJ,CAAe,KAAK,IAAL,GAAY,IAA3B,CAAlB;AACH,C,CAED;AACA;;;AACAE,mBAAmB,CAACI,SAApB,CAA8BC,eAA9B,GAAgD,UAAUC,OAAV,EAAmB;AAC/D,MAAIC,kBAAkB,GAAG,EAAzB,CAD+D,CACjC;;AAE9B,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,OAAO,CAACG,MAA5B,EAAoCD,CAAC,EAArC,EAAyC;AACrC,QAAIE,KAAK,GAAGJ,OAAO,CAACE,CAAD,CAAnB;;AAEA,QAAIE,KAAK,CAACD,MAAN,GAAe,CAAnB,EAAsB;AAClB;AACH;;AAED,QAAIE,YAAY,GAAGD,KAAK,CAAC,CAAD,CAAxB;AACA,QAAIE,OAAO,GAAGF,KAAK,CAAC,CAAD,CAAnB;AACA,QAAIG,QAAQ,GAAGH,KAAK,CAAC,CAAD,CAApB;AACA,QAAII,SAAS,GAAGJ,KAAK,CAAC,CAAD,CAArB;AACA,QAAIK,OAAO,GAAGL,KAAK,CAACM,KAAN,CAAY,CAAZ,EAAeC,IAAf,CAAoB,GAApB,CAAd,CAXqC,CAWI;AAEzC;;AACA,QAAI,CAACC,QAAQ,CAACN,OAAD,CAAT,IAAsB,CAACM,QAAQ,CAACL,QAAD,CAA/B,IAA6C,CAACK,QAAQ,CAACJ,SAAD,CAA1D,EAAuE;AACnEK,MAAAA,OAAO,CAACC,GAAR,CAAYV,KAAZ;AACH;;AAED,QAAIW,aAAa,GAAG,KAAKC,GAAL,CAASV,OAAT,EAAkBC,QAAlB,EAA4BC,SAA5B,EAAuCH,YAAvC,EAAqDI,OAArD,CAApB;AACAR,IAAAA,kBAAkB,CAACc,aAAD,CAAlB,GAAoCV,YAApC;AACH,GAvB8D,CAyB/D;;;AACA,OAAKV,UAAL,CAAgBsB,MAAhB;AACA,OAAKpB,UAAL,CAAgBoB,MAAhB;AAEA,SAAOhB,kBAAP;AACH,CA9BD;;AAgCAP,mBAAmB,CAACI,SAApB,CAA8BkB,GAA9B,GAAoC,UAAUV,OAAV,EAAmBC,QAAnB,EAA6BC,SAA7B,EAAwCH,YAAxC,EAAsDI,OAAtD,EAA+D;AAC/F,MAAIM,aAAa,GAAG,KAAKpB,UAAL,CAAgBuB,QAApC;AACA,MAAIC,MAAM,GAAG,KAAKtB,UAAL,CAAgBqB,QAA7B;AAEA,OAAKvB,UAAL,CAAgByB,QAAhB,CAAyBd,OAAzB;AACA,OAAKX,UAAL,CAAgByB,QAAhB,CAAyBb,QAAzB;AACA,OAAKZ,UAAL,CAAgByB,QAAhB,CAAyBZ,SAAzB;AACA,OAAKb,UAAL,CAAgB0B,MAAhB,CAAuBF,MAAvB;AACA,OAAKtB,UAAL,CAAgByB,SAAhB,CAA0BjB,YAAY,GAAG,GAAf,GAAqBI,OAA/C;AAEA,SAAOM,aAAP;AACH,CAXD;;AAaArB,mBAAmB,CAACI,SAApB,CAA8ByB,UAA9B,GAA2C,UAAUC,MAAV,EAAkBC,MAAlB,EAA0B;AACjE,MAAIC,OAAO,GAAG,KAAK9B,UAAL,CAAgB4B,MAAhB,CAAd;;AACA,MAAIE,OAAO,IAAI,IAAf,EAAqB;AACjBA,IAAAA,OAAO,GAAG,EAAV;AACH;;AACDA,EAAAA,OAAO,CAACC,IAAR,CAAaF,MAAb;AAEA,OAAK7B,UAAL,CAAgB4B,MAAhB,IAA0BE,OAA1B;AACH,CARD;;AAUAhC,mBAAmB,CAACI,SAApB,CAA8B8B,iBAA9B,GAAkD,YAAY;AAC1D,MAAIC,MAAM,GAAG,IAAIrC,UAAJ,EAAb;AACA,MAAIsC,aAAa,GAAGC,MAAM,CAACC,IAAP,CAAY,KAAKpC,UAAjB,EAA6BO,MAAjD;AACA0B,EAAAA,MAAM,CAACR,MAAP,CAAcS,aAAd;;AACA,OAAK,IAAIG,GAAT,IAAgB,KAAKrC,UAArB,EAAiC;AAC7B,QAAIsC,MAAM,GAAG,KAAKtC,UAAL,CAAgBqC,GAAhB,CAAb,CAD6B,CACO;;AACpC,QAAIE,eAAe,GAAGD,MAAM,CAAC/B,MAA7B;AACA0B,IAAAA,MAAM,CAACR,MAAP,CAAce,QAAQ,CAACH,GAAD,CAAtB;AACAJ,IAAAA,MAAM,CAACR,MAAP,CAAcc,eAAd;;AACA,SAAK,IAAIjC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGgC,MAAM,CAAC/B,MAA3B,EAAmCD,CAAC,EAApC,EAAwC;AACpC2B,MAAAA,MAAM,CAACR,MAAP,CAAca,MAAM,CAAChC,CAAD,CAApB;AACH;AACJ;;AACD,SAAO2B,MAAM,CAACZ,MAAP,EAAP,CAb0D,CAajC;AAC5B,CAdD,C,CAgBA;;;AACAvB,mBAAmB,CAACI,SAApB,CAA8BuC,cAA9B,GAA+C,UAAUC,YAAV,EAAwB;AACnE,OAAK3C,UAAL,GAAkB,IAAIH,UAAJ,CAAe8C,YAAf,CAAlB;AACA,SAAO,IAAP;AACH,CAHD,C,CAKA;;;AACA5C,mBAAmB,CAACI,SAApB,CAA8ByC,aAA9B,GAA8C,UAAUD,YAAV,EAAwB;AAClE,OAAKzC,UAAL,GAAkB,IAAIL,UAAJ,CAAe8C,YAAf,CAAlB;AACA,SAAO,IAAP;AACH,CAHD,C,CAKA;;;AACA5C,mBAAmB,CAACI,SAApB,CAA8B0C,aAA9B,GAA8C,UAAUF,YAAV,EAAwB;AAClE,MAAIT,MAAM,GAAG,IAAIrC,UAAJ,CAAe8C,YAAf,CAAb;AACAT,EAAAA,MAAM,CAACX,QAAP,GAAkB,CAAlB;AACA,OAAKtB,UAAL,GAAkB,EAAlB;AACAiC,EAAAA,MAAM,CAACY,OAAP,GAJkE,CAI/C;;AACnB,SAAO,IAAP,EAAa;AACT,QAAIZ,MAAM,CAACA,MAAP,CAAc1B,MAAd,GAAuB0B,MAAM,CAACX,QAAP,GAAkB,CAA7C,EAAgD;AAC5C;AACH;;AACD,QAAIe,GAAG,GAAGJ,MAAM,CAACY,OAAP,EAAV;AACA,QAAIN,eAAe,GAAGN,MAAM,CAACY,OAAP,EAAtB;;AACA,SAAK,IAAIvC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGiC,eAApB,EAAqCjC,CAAC,EAAtC,EAA0C;AACtC,UAAIwC,KAAK,GAAGb,MAAM,CAACY,OAAP,EAAZ;AACA,WAAKlB,UAAL,CAAgBU,GAAhB,EAAqBS,KAArB;AACH;AACJ;;AACD,SAAO,IAAP;AACH,CAjBD;AAmBA;;;;;;;AAKAhD,mBAAmB,CAACI,SAApB,CAA8B6C,WAA9B,GAA4C,UAAUC,iBAAV,EAA6B;AACrE,MAAI7B,aAAa,GAAGqB,QAAQ,CAACQ,iBAAD,CAA5B;;AACA,MAAIC,KAAK,CAAC9B,aAAD,CAAT,EAA0B;AACtB;AACA,WAAO,EAAP;AACH;;AACD,MAAII,MAAM,GAAG,KAAKxB,UAAL,CAAgBmD,MAAhB,CAAuB/B,aAAa,GAAG,CAAvC,CAAb;AACA,SAAO,KAAKlB,UAAL,CAAgBkD,SAAhB,CAA0B5B,MAA1B,CAAP;AACH,CARD;;AAUA6B,MAAM,CAACC,OAAP,GAAiBvD,mBAAjB","sourcesContent":["/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n\"use strict\";\n\nvar ByteBuffer = require(\"../util/ByteBuffer\");\n\n/**\n * TokenInfoDictionary\n * @constructor\n */\nfunction TokenInfoDictionary() {\n    this.dictionary = new ByteBuffer(10 * 1024 * 1024);\n    this.target_map = {};  // trie_id (of surface form) -> token_info_id (of token)\n    this.pos_buffer = new ByteBuffer(10 * 1024 * 1024);\n}\n\n// left_id right_id word_cost ...\n// ^ this position is token_info_id\nTokenInfoDictionary.prototype.buildDictionary = function (entries) {\n    var dictionary_entries = {};  // using as hashmap, string -> string (word_id -> surface_form) to build dictionary\n\n    for (var i = 0; i < entries.length; i++) {\n        var entry = entries[i];\n\n        if (entry.length < 4) {\n            continue;\n        }\n\n        var surface_form = entry[0];\n        var left_id = entry[1];\n        var right_id = entry[2];\n        var word_cost = entry[3];\n        var feature = entry.slice(4).join(\",\");  // TODO Optimize\n\n        // Assertion\n        if (!isFinite(left_id) || !isFinite(right_id) || !isFinite(word_cost)) {\n            console.log(entry);\n        }\n\n        var token_info_id = this.put(left_id, right_id, word_cost, surface_form, feature);\n        dictionary_entries[token_info_id] = surface_form;\n    }\n\n    // Remove last unused area\n    this.dictionary.shrink();\n    this.pos_buffer.shrink();\n\n    return dictionary_entries;\n};\n\nTokenInfoDictionary.prototype.put = function (left_id, right_id, word_cost, surface_form, feature) {\n    var token_info_id = this.dictionary.position;\n    var pos_id = this.pos_buffer.position;\n\n    this.dictionary.putShort(left_id);\n    this.dictionary.putShort(right_id);\n    this.dictionary.putShort(word_cost);\n    this.dictionary.putInt(pos_id);\n    this.pos_buffer.putString(surface_form + \",\" + feature);\n\n    return token_info_id;\n};\n\nTokenInfoDictionary.prototype.addMapping = function (source, target) {\n    var mapping = this.target_map[source];\n    if (mapping == null) {\n        mapping = [];\n    }\n    mapping.push(target);\n\n    this.target_map[source] = mapping;\n};\n\nTokenInfoDictionary.prototype.targetMapToBuffer = function () {\n    var buffer = new ByteBuffer();\n    var map_keys_size = Object.keys(this.target_map).length;\n    buffer.putInt(map_keys_size);\n    for (var key in this.target_map) {\n        var values = this.target_map[key];  // Array\n        var map_values_size = values.length;\n        buffer.putInt(parseInt(key));\n        buffer.putInt(map_values_size);\n        for (var i = 0; i < values.length; i++) {\n            buffer.putInt(values[i]);\n        }\n    }\n    return buffer.shrink();  // Shrink-ed Typed Array\n};\n\n// from tid.dat\nTokenInfoDictionary.prototype.loadDictionary = function (array_buffer) {\n    this.dictionary = new ByteBuffer(array_buffer);\n    return this;\n};\n\n// from tid_pos.dat\nTokenInfoDictionary.prototype.loadPosVector = function (array_buffer) {\n    this.pos_buffer = new ByteBuffer(array_buffer);\n    return this;\n};\n\n// from tid_map.dat\nTokenInfoDictionary.prototype.loadTargetMap = function (array_buffer) {\n    var buffer = new ByteBuffer(array_buffer);\n    buffer.position = 0;\n    this.target_map = {};\n    buffer.readInt();  // map_keys_size\n    while (true) {\n        if (buffer.buffer.length < buffer.position + 1) {\n            break;\n        }\n        var key = buffer.readInt();\n        var map_values_size = buffer.readInt();\n        for (var i = 0; i < map_values_size; i++) {\n            var value = buffer.readInt();\n            this.addMapping(key, value);\n        }\n    }\n    return this;\n};\n\n/**\n * Look up features in the dictionary\n * @param {string} token_info_id_str Word ID to look up\n * @returns {string} Features string concatenated by \",\"\n */\nTokenInfoDictionary.prototype.getFeatures = function (token_info_id_str) {\n    var token_info_id = parseInt(token_info_id_str);\n    if (isNaN(token_info_id)) {\n        // TODO throw error\n        return \"\";\n    }\n    var pos_id = this.dictionary.getInt(token_info_id + 6);\n    return this.pos_buffer.getString(pos_id);\n};\n\nmodule.exports = TokenInfoDictionary;\n"]},"metadata":{},"sourceType":"script"}