{"ast":null,"code":"/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\"use strict\";\n\nvar ViterbiBuilder = require(\"./viterbi/ViterbiBuilder\");\n\nvar ViterbiSearcher = require(\"./viterbi/ViterbiSearcher\");\n\nvar IpadicFormatter = require(\"./util/IpadicFormatter\");\n\nvar PUNCTUATION = /、|。/;\n/**\n * Tokenizer\n * @param {DynamicDictionaries} dic Dictionaries used by this tokenizer\n * @constructor\n */\n\nfunction Tokenizer(dic) {\n  this.token_info_dictionary = dic.token_info_dictionary;\n  this.unknown_dictionary = dic.unknown_dictionary;\n  this.viterbi_builder = new ViterbiBuilder(dic);\n  this.viterbi_searcher = new ViterbiSearcher(dic.connection_costs);\n  this.formatter = new IpadicFormatter(); // TODO Other dictionaries\n}\n/**\n * Split into sentence by punctuation\n * @param {string} input Input text\n * @returns {Array.<string>} Sentences end with punctuation\n */\n\n\nTokenizer.splitByPunctuation = function (input) {\n  var sentences = [];\n  var tail = input;\n\n  while (true) {\n    if (tail === \"\") {\n      break;\n    }\n\n    var index = tail.search(PUNCTUATION);\n\n    if (index < 0) {\n      sentences.push(tail);\n      break;\n    }\n\n    sentences.push(tail.substring(0, index + 1));\n    tail = tail.substring(index + 1);\n  }\n\n  return sentences;\n};\n/**\n * Tokenize text\n * @param {string} text Input text to analyze\n * @returns {Array} Tokens\n */\n\n\nTokenizer.prototype.tokenize = function (text) {\n  var sentences = Tokenizer.splitByPunctuation(text);\n  var tokens = [];\n\n  for (var i = 0; i < sentences.length; i++) {\n    var sentence = sentences[i];\n    this.tokenizeForSentence(sentence, tokens);\n  }\n\n  return tokens;\n};\n\nTokenizer.prototype.tokenizeForSentence = function (sentence, tokens) {\n  if (tokens == null) {\n    tokens = [];\n  }\n\n  var lattice = this.getLattice(sentence);\n  var best_path = this.viterbi_searcher.search(lattice);\n  var last_pos = 0;\n\n  if (tokens.length > 0) {\n    last_pos = tokens[tokens.length - 1].word_position;\n  }\n\n  for (var j = 0; j < best_path.length; j++) {\n    var node = best_path[j];\n    var token, features, features_line;\n\n    if (node.type === \"KNOWN\") {\n      features_line = this.token_info_dictionary.getFeatures(node.name);\n\n      if (features_line == null) {\n        features = [];\n      } else {\n        features = features_line.split(\",\");\n      }\n\n      token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, features);\n    } else if (node.type === \"UNKNOWN\") {\n      // Unknown word\n      features_line = this.unknown_dictionary.getFeatures(node.name);\n\n      if (features_line == null) {\n        features = [];\n      } else {\n        features = features_line.split(\",\");\n      }\n\n      token = this.formatter.formatUnknownEntry(node.name, last_pos + node.start_pos, node.type, features, node.surface_form);\n    } else {\n      // TODO User dictionary\n      token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, []);\n    }\n\n    tokens.push(token);\n  }\n\n  return tokens;\n};\n/**\n * Build word lattice\n * @param {string} text Input text to analyze\n * @returns {ViterbiLattice} Word lattice\n */\n\n\nTokenizer.prototype.getLattice = function (text) {\n  return this.viterbi_builder.build(text);\n};\n\nmodule.exports = Tokenizer;","map":{"version":3,"sources":["/home/byungchan/Projects/react/JapaneseQuiz/client/node_modules/kuromoji/src/Tokenizer.js"],"names":["ViterbiBuilder","require","ViterbiSearcher","IpadicFormatter","PUNCTUATION","Tokenizer","dic","token_info_dictionary","unknown_dictionary","viterbi_builder","viterbi_searcher","connection_costs","formatter","splitByPunctuation","input","sentences","tail","index","search","push","substring","prototype","tokenize","text","tokens","i","length","sentence","tokenizeForSentence","lattice","getLattice","best_path","last_pos","word_position","j","node","token","features","features_line","type","getFeatures","name","split","formatEntry","start_pos","formatUnknownEntry","surface_form","build","module","exports"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA;;AAEA,IAAIA,cAAc,GAAGC,OAAO,CAAC,0BAAD,CAA5B;;AACA,IAAIC,eAAe,GAAGD,OAAO,CAAC,2BAAD,CAA7B;;AACA,IAAIE,eAAe,GAAGF,OAAO,CAAC,wBAAD,CAA7B;;AAEA,IAAIG,WAAW,GAAG,KAAlB;AAEA;;;;;;AAKA,SAASC,SAAT,CAAmBC,GAAnB,EAAwB;AACpB,OAAKC,qBAAL,GAA6BD,GAAG,CAACC,qBAAjC;AACA,OAAKC,kBAAL,GAA0BF,GAAG,CAACE,kBAA9B;AACA,OAAKC,eAAL,GAAuB,IAAIT,cAAJ,CAAmBM,GAAnB,CAAvB;AACA,OAAKI,gBAAL,GAAwB,IAAIR,eAAJ,CAAoBI,GAAG,CAACK,gBAAxB,CAAxB;AACA,OAAKC,SAAL,GAAiB,IAAIT,eAAJ,EAAjB,CALoB,CAKqB;AAC5C;AAED;;;;;;;AAKAE,SAAS,CAACQ,kBAAV,GAA+B,UAAUC,KAAV,EAAiB;AAC5C,MAAIC,SAAS,GAAG,EAAhB;AACA,MAAIC,IAAI,GAAGF,KAAX;;AACA,SAAO,IAAP,EAAa;AACT,QAAIE,IAAI,KAAK,EAAb,EAAiB;AACb;AACH;;AACD,QAAIC,KAAK,GAAGD,IAAI,CAACE,MAAL,CAAYd,WAAZ,CAAZ;;AACA,QAAIa,KAAK,GAAG,CAAZ,EAAe;AACXF,MAAAA,SAAS,CAACI,IAAV,CAAeH,IAAf;AACA;AACH;;AACDD,IAAAA,SAAS,CAACI,IAAV,CAAeH,IAAI,CAACI,SAAL,CAAe,CAAf,EAAkBH,KAAK,GAAG,CAA1B,CAAf;AACAD,IAAAA,IAAI,GAAGA,IAAI,CAACI,SAAL,CAAeH,KAAK,GAAG,CAAvB,CAAP;AACH;;AACD,SAAOF,SAAP;AACH,CAhBD;AAkBA;;;;;;;AAKAV,SAAS,CAACgB,SAAV,CAAoBC,QAApB,GAA+B,UAAUC,IAAV,EAAgB;AAC3C,MAAIR,SAAS,GAAGV,SAAS,CAACQ,kBAAV,CAA6BU,IAA7B,CAAhB;AACA,MAAIC,MAAM,GAAG,EAAb;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGV,SAAS,CAACW,MAA9B,EAAsCD,CAAC,EAAvC,EAA2C;AACvC,QAAIE,QAAQ,GAAGZ,SAAS,CAACU,CAAD,CAAxB;AACA,SAAKG,mBAAL,CAAyBD,QAAzB,EAAmCH,MAAnC;AACH;;AACD,SAAOA,MAAP;AACH,CARD;;AAUAnB,SAAS,CAACgB,SAAV,CAAoBO,mBAApB,GAA0C,UAAUD,QAAV,EAAoBH,MAApB,EAA4B;AAClE,MAAIA,MAAM,IAAI,IAAd,EAAoB;AAChBA,IAAAA,MAAM,GAAG,EAAT;AACH;;AACD,MAAIK,OAAO,GAAG,KAAKC,UAAL,CAAgBH,QAAhB,CAAd;AACA,MAAII,SAAS,GAAG,KAAKrB,gBAAL,CAAsBQ,MAAtB,CAA6BW,OAA7B,CAAhB;AACA,MAAIG,QAAQ,GAAG,CAAf;;AACA,MAAIR,MAAM,CAACE,MAAP,GAAgB,CAApB,EAAuB;AACnBM,IAAAA,QAAQ,GAAGR,MAAM,CAACA,MAAM,CAACE,MAAP,GAAgB,CAAjB,CAAN,CAA0BO,aAArC;AACH;;AAED,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,SAAS,CAACL,MAA9B,EAAsCQ,CAAC,EAAvC,EAA2C;AACvC,QAAIC,IAAI,GAAGJ,SAAS,CAACG,CAAD,CAApB;AAEA,QAAIE,KAAJ,EAAWC,QAAX,EAAqBC,aAArB;;AACA,QAAIH,IAAI,CAACI,IAAL,KAAc,OAAlB,EAA2B;AACvBD,MAAAA,aAAa,GAAG,KAAK/B,qBAAL,CAA2BiC,WAA3B,CAAuCL,IAAI,CAACM,IAA5C,CAAhB;;AACA,UAAIH,aAAa,IAAI,IAArB,EAA2B;AACvBD,QAAAA,QAAQ,GAAG,EAAX;AACH,OAFD,MAEO;AACHA,QAAAA,QAAQ,GAAGC,aAAa,CAACI,KAAd,CAAoB,GAApB,CAAX;AACH;;AACDN,MAAAA,KAAK,GAAG,KAAKxB,SAAL,CAAe+B,WAAf,CAA2BR,IAAI,CAACM,IAAhC,EAAsCT,QAAQ,GAAGG,IAAI,CAACS,SAAtD,EAAiET,IAAI,CAACI,IAAtE,EAA4EF,QAA5E,CAAR;AACH,KARD,MAQO,IAAIF,IAAI,CAACI,IAAL,KAAc,SAAlB,EAA6B;AAChC;AACAD,MAAAA,aAAa,GAAG,KAAK9B,kBAAL,CAAwBgC,WAAxB,CAAoCL,IAAI,CAACM,IAAzC,CAAhB;;AACA,UAAIH,aAAa,IAAI,IAArB,EAA2B;AACvBD,QAAAA,QAAQ,GAAG,EAAX;AACH,OAFD,MAEO;AACHA,QAAAA,QAAQ,GAAGC,aAAa,CAACI,KAAd,CAAoB,GAApB,CAAX;AACH;;AACDN,MAAAA,KAAK,GAAG,KAAKxB,SAAL,CAAeiC,kBAAf,CAAkCV,IAAI,CAACM,IAAvC,EAA6CT,QAAQ,GAAGG,IAAI,CAACS,SAA7D,EAAwET,IAAI,CAACI,IAA7E,EAAmFF,QAAnF,EAA6FF,IAAI,CAACW,YAAlG,CAAR;AACH,KATM,MASA;AACH;AACAV,MAAAA,KAAK,GAAG,KAAKxB,SAAL,CAAe+B,WAAf,CAA2BR,IAAI,CAACM,IAAhC,EAAsCT,QAAQ,GAAGG,IAAI,CAACS,SAAtD,EAAiET,IAAI,CAACI,IAAtE,EAA4E,EAA5E,CAAR;AACH;;AAEDf,IAAAA,MAAM,CAACL,IAAP,CAAYiB,KAAZ;AACH;;AAED,SAAOZ,MAAP;AACH,CAzCD;AA2CA;;;;;;;AAKAnB,SAAS,CAACgB,SAAV,CAAoBS,UAApB,GAAiC,UAAUP,IAAV,EAAgB;AAC7C,SAAO,KAAKd,eAAL,CAAqBsC,KAArB,CAA2BxB,IAA3B,CAAP;AACH,CAFD;;AAIAyB,MAAM,CAACC,OAAP,GAAiB5C,SAAjB","sourcesContent":["/*\n * Copyright 2014 Takuya Asano\n * Copyright 2010-2014 Atilika Inc. and contributors\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n\"use strict\";\n\nvar ViterbiBuilder = require(\"./viterbi/ViterbiBuilder\");\nvar ViterbiSearcher = require(\"./viterbi/ViterbiSearcher\");\nvar IpadicFormatter = require(\"./util/IpadicFormatter\");\n\nvar PUNCTUATION = /、|。/;\n\n/**\n * Tokenizer\n * @param {DynamicDictionaries} dic Dictionaries used by this tokenizer\n * @constructor\n */\nfunction Tokenizer(dic) {\n    this.token_info_dictionary = dic.token_info_dictionary;\n    this.unknown_dictionary = dic.unknown_dictionary;\n    this.viterbi_builder = new ViterbiBuilder(dic);\n    this.viterbi_searcher = new ViterbiSearcher(dic.connection_costs);\n    this.formatter = new IpadicFormatter();  // TODO Other dictionaries\n}\n\n/**\n * Split into sentence by punctuation\n * @param {string} input Input text\n * @returns {Array.<string>} Sentences end with punctuation\n */\nTokenizer.splitByPunctuation = function (input) {\n    var sentences = [];\n    var tail = input;\n    while (true) {\n        if (tail === \"\") {\n            break;\n        }\n        var index = tail.search(PUNCTUATION);\n        if (index < 0) {\n            sentences.push(tail);\n            break;\n        }\n        sentences.push(tail.substring(0, index + 1));\n        tail = tail.substring(index + 1);\n    }\n    return sentences;\n};\n\n/**\n * Tokenize text\n * @param {string} text Input text to analyze\n * @returns {Array} Tokens\n */\nTokenizer.prototype.tokenize = function (text) {\n    var sentences = Tokenizer.splitByPunctuation(text);\n    var tokens = [];\n    for (var i = 0; i < sentences.length; i++) {\n        var sentence = sentences[i];\n        this.tokenizeForSentence(sentence, tokens);\n    }\n    return tokens;\n};\n\nTokenizer.prototype.tokenizeForSentence = function (sentence, tokens) {\n    if (tokens == null) {\n        tokens = [];\n    }\n    var lattice = this.getLattice(sentence);\n    var best_path = this.viterbi_searcher.search(lattice);\n    var last_pos = 0;\n    if (tokens.length > 0) {\n        last_pos = tokens[tokens.length - 1].word_position;\n    }\n\n    for (var j = 0; j < best_path.length; j++) {\n        var node = best_path[j];\n\n        var token, features, features_line;\n        if (node.type === \"KNOWN\") {\n            features_line = this.token_info_dictionary.getFeatures(node.name);\n            if (features_line == null) {\n                features = [];\n            } else {\n                features = features_line.split(\",\");\n            }\n            token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, features);\n        } else if (node.type === \"UNKNOWN\") {\n            // Unknown word\n            features_line = this.unknown_dictionary.getFeatures(node.name);\n            if (features_line == null) {\n                features = [];\n            } else {\n                features = features_line.split(\",\");\n            }\n            token = this.formatter.formatUnknownEntry(node.name, last_pos + node.start_pos, node.type, features, node.surface_form);\n        } else {\n            // TODO User dictionary\n            token = this.formatter.formatEntry(node.name, last_pos + node.start_pos, node.type, []);\n        }\n\n        tokens.push(token);\n    }\n\n    return tokens;\n};\n\n/**\n * Build word lattice\n * @param {string} text Input text to analyze\n * @returns {ViterbiLattice} Word lattice\n */\nTokenizer.prototype.getLattice = function (text) {\n    return this.viterbi_builder.build(text);\n};\n\nmodule.exports = Tokenizer;\n"]},"metadata":{},"sourceType":"script"}